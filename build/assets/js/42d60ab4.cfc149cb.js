"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[488],{7312:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>_,frontMatter:()=>t,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module3-isaac/sim-to-real","title":"Sim-to-Real Transfer","description":"Introduction to Sim-to-Real Transfer","source":"@site/docs/module3-isaac/sim-to-real.md","sourceDirName":"module3-isaac","slug":"/module3-isaac/sim-to-real","permalink":"/docs/module3-isaac/sim-to-real","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"modules","previous":{"title":"Reinforcement Learning in Robotics with Isaac Sim","permalink":"/docs/module3-isaac/reinforcement-learning"},"next":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/docs/module4-vla/intro"}}');var i=r(4848),s=r(8453);const t={},o="Sim-to-Real Transfer",l={},c=[{value:"Introduction to Sim-to-Real Transfer",id:"introduction-to-sim-to-real-transfer",level:2},{value:"The Reality Gap Challenge",id:"the-reality-gap-challenge",level:2},{value:"Definition of the Reality Gap",id:"definition-of-the-reality-gap",level:3},{value:"Quantifying the Reality Gap",id:"quantifying-the-reality-gap",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Concept and Implementation",id:"concept-and-implementation",level:3},{value:"Advanced Domain Randomization",id:"advanced-domain-randomization",level:3},{value:"System Identification",id:"system-identification",level:2},{value:"Model Parameter Estimation",id:"model-parameter-estimation",level:3},{value:"Transfer Learning Techniques",id:"transfer-learning-techniques",level:2},{value:"Fine-Tuning Approaches",id:"fine-tuning-approaches",level:3},{value:"Domain Adaptation Networks",id:"domain-adaptation-networks",level:3},{value:"Isaac Sim-Specific Transfer Techniques",id:"isaac-sim-specific-transfer-techniques",level:2},{value:"Isaac Sim Calibration Tools",id:"isaac-sim-calibration-tools",level:3},{value:"Sensor Simulation Calibration",id:"sensor-simulation-calibration",level:3},{value:"Real-World Deployment Strategies",id:"real-world-deployment-strategies",level:2},{value:"Gradual Deployment",id:"gradual-deployment",level:3},{value:"Performance Monitoring and Adaptation",id:"performance-monitoring-and-adaptation",level:3},{value:"Advanced Transfer Techniques",id:"advanced-transfer-techniques",level:2},{value:"Sim-to-Real with Real-to-Sim Feedback",id:"sim-to-real-with-real-to-sim-feedback",level:3},{value:"Few-Shot Adaptation",id:"few-shot-adaptation",level:3},{value:"Evaluation and Validation",id:"evaluation-and-validation",level:2},{value:"Transfer Success Metrics",id:"transfer-success-metrics",level:3},{value:"Best Practices for Successful Transfer",id:"best-practices-for-successful-transfer",level:2},{value:"Pre-Transfer Validation",id:"pre-transfer-validation",level:3},{value:"Continuous Improvement",id:"continuous-improvement",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"sim-to-real-transfer",children:"Sim-to-Real Transfer"})}),"\n",(0,i.jsx)(n.h2,{id:"introduction-to-sim-to-real-transfer",children:"Introduction to Sim-to-Real Transfer"}),"\n",(0,i.jsx)(n.p,{children:'Sim-to-real transfer is the process of taking robotic behaviors, policies, or models trained in simulation and successfully deploying them on real hardware. This approach is crucial for humanoid robotics, where real-world training can be expensive, time-consuming, and potentially dangerous. The goal is to minimize the "reality gap" between simulation and the real world while maintaining the benefits of simulation-based training.'}),"\n",(0,i.jsx)(n.h2,{id:"the-reality-gap-challenge",children:"The Reality Gap Challenge"}),"\n",(0,i.jsx)(n.h3,{id:"definition-of-the-reality-gap",children:"Definition of the Reality Gap"}),"\n",(0,i.jsx)(n.p,{children:"The reality gap encompasses all the differences between simulation and reality that can cause a policy trained in simulation to fail when deployed on real hardware:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visual differences"}),": Lighting, textures, colors, and rendering artifacts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Physics differences"}),": Friction, mass, inertia, compliance, and contact models"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor differences"}),": Noise, latency, resolution, and calibration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuator differences"}),": Response time, precision, and force application"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Environmental differences"}),": Unmodeled dynamics and disturbances"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"quantifying-the-reality-gap",children:"Quantifying the Reality Gap"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import numpy as np\r\n\r\nclass RealityGapAnalyzer:\r\n    def __init__(self):\r\n        self.sim_data = []\r\n        self.real_data = []\r\n\r\n    def measure_reality_gap(self, sim_observations, real_observations):\r\n        # Calculate various gap metrics\r\n        visual_gap = self.calculate_visual_difference(sim_observations, real_observations)\r\n        dynamics_gap = self.calculate_dynamics_difference(sim_observations, real_observations)\r\n        sensor_gap = self.calculate_sensor_difference(sim_observations, real_observations)\r\n\r\n        total_gap = {\r\n            'visual': visual_gap,\r\n            'dynamics': dynamics_gap,\r\n            'sensor': sensor_gap,\r\n            'combined': np.sqrt(visual_gap**2 + dynamics_gap**2 + sensor_gap**2)\r\n        }\r\n\r\n        return total_gap\r\n\r\n    def calculate_visual_difference(self, sim_obs, real_obs):\r\n        # Compare visual features between sim and real\r\n        return np.mean(np.abs(sim_obs['rgb'] - real_obs['rgb']))\r\n\r\n    def calculate_dynamics_difference(self, sim_obs, real_obs):\r\n        # Compare dynamics behavior\r\n        return np.mean(np.abs(sim_obs['velocities'] - real_obs['velocities']))\n"})}),"\n",(0,i.jsx)(n.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,i.jsx)(n.h3,{id:"concept-and-implementation",children:"Concept and Implementation"}),"\n",(0,i.jsx)(n.p,{children:"Domain randomization is a key technique for improving sim-to-real transfer by training policies on a wide variety of simulated conditions:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class DomainRandomizer:\r\n    def __init__(self):\r\n        self.param_ranges = {\r\n            'robot_mass': [0.8, 1.2],           # \xb120% mass variation\r\n            'friction_coeff': [0.3, 1.0],      # Friction range\r\n            'restitution': [0.0, 0.3],         # Bounciness range\r\n            'actuator_strength': [0.7, 1.3],   # Force variation\r\n            'sensor_noise_std': [0.0, 0.1],    # Sensor noise range\r\n            'light_intensity': [0.5, 2.0],     # Lighting variation\r\n            'camera_offset': [-0.05, 0.05]     # Camera position variation\r\n        }\r\n\r\n    def randomize_environment(self, env):\r\n        # Randomize physics parameters\r\n        robot_mass = np.random.uniform(*self.param_ranges['robot_mass'])\r\n        env.set_robot_mass(robot_mass)\r\n\r\n        friction = np.random.uniform(*self.param_ranges['friction_coeff'])\r\n        env.set_friction_coefficient(friction)\r\n\r\n        # Randomize visual properties\r\n        light_intensity = np.random.uniform(*self.param_ranges['light_intensity'])\r\n        env.set_light_intensity(light_intensity)\r\n\r\n        # Randomize sensor properties\r\n        sensor_noise = np.random.uniform(*self.param_ranges['sensor_noise_std'])\r\n        env.set_sensor_noise(sensor_noise)\r\n\r\n    def adaptive_randomization(self, performance_history):\r\n        # Adjust randomization based on performance\r\n        if np.mean(performance_history[-10:]) < 0.6:  # Poor performance\r\n            # Reduce randomization range to focus on realistic parameters\r\n            self.shrink_randomization_range()\r\n        elif np.mean(performance_history[-10:]) > 0.9:  # Good performance\r\n            # Increase randomization range for robustness\r\n            self.expand_randomization_range()\r\n\r\n    def shrink_randomization_range(self):\r\n        for param in self.param_ranges:\r\n            current_range = self.param_ranges[param]\r\n            center = (current_range[0] + current_range[1]) / 2\r\n            width = (current_range[1] - current_range[0]) * 0.8  # Reduce by 20%\r\n            self.param_ranges[param] = [\r\n                center - width/2,\r\n                center + width/2\r\n            ]\r\n\r\n    def expand_randomization_range(self):\r\n        for param in self.param_ranges:\r\n            current_range = self.param_ranges[param]\r\n            center = (current_range[0] + current_range[1]) / 2\r\n            width = (current_range[1] - current_range[0]) * 1.2  # Increase by 20%\r\n            new_range = [\r\n                max(center - width/2, self.original_ranges[param][0]),\r\n                min(center + width/2, self.original_ranges[param][1])\r\n            ]\r\n            self.param_ranges[param] = new_range\n"})}),"\n",(0,i.jsx)(n.h3,{id:"advanced-domain-randomization",children:"Advanced Domain Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class AdvancedDomainRandomizer:\r\n    def __init__(self):\r\n        self.visual_randomizer = self.setup_visual_randomizer()\r\n        self.physics_randomizer = self.setup_physics_randomizer()\r\n        self.sensor_randomizer = self.setup_sensor_randomizer()\r\n\r\n    def setup_visual_randomizer(self):\r\n        return {\r\n            'color_jitter': True,\r\n            'brightness_range': [0.7, 1.3],\r\n            'contrast_range': [0.8, 1.2],\r\n            'saturation_range': [0.8, 1.2],\r\n            'hue_range': [-0.1, 0.1],\r\n            'gaussian_noise': [0.0, 0.05],\r\n            'motion_blur': [0.0, 0.1]\r\n        }\r\n\r\n    def setup_physics_randomizer(self):\r\n        return {\r\n            'mass_variation': [0.8, 1.2],\r\n            'com_offset': [-0.02, 0.02],  # Center of mass offset\r\n            'inertia_scaling': [0.9, 1.1],\r\n            'joint_friction': [0.0, 0.1],\r\n            'damping_coefficient': [0.8, 1.2],\r\n            'contact_stiffness': [0.5, 2.0]\r\n        }\r\n\r\n    def setup_sensor_randomizer(self):\r\n        return {\r\n            'imu_noise': [0.001, 0.01],      # Accelerometer noise\r\n            'gyro_noise': [0.0001, 0.001],  # Gyroscope noise\r\n            'delay_range': [0.0, 0.05],     # Sensor delay in seconds\r\n            'bias_drift': [0.0, 0.001],     # Slow bias drift\r\n            'scale_error': [0.99, 1.01]     # Scale factor error\r\n        }\r\n\r\n    def apply_randomization(self, env, step_count):\r\n        # Apply different levels of randomization over training\r\n        intensity = self.get_randomization_intensity(step_count)\r\n\r\n        self.apply_visual_randomization(env, intensity)\r\n        self.apply_physics_randomization(env, intensity)\r\n        self.apply_sensor_randomization(env, intensity)\r\n\r\n    def get_randomization_intensity(self, step_count):\r\n        # Gradually increase randomization during training\r\n        max_steps = 1000000\r\n        base_intensity = min(step_count / max_steps, 1.0)\r\n        return base_intensity\n"})}),"\n",(0,i.jsx)(n.h2,{id:"system-identification",children:"System Identification"}),"\n",(0,i.jsx)(n.h3,{id:"model-parameter-estimation",children:"Model Parameter Estimation"}),"\n",(0,i.jsx)(n.p,{children:"Accurate system identification helps bridge the sim-to-real gap by identifying real-world parameters:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class SystemIdentifier:\r\n    def __init__(self, robot_model):\r\n        self.robot_model = robot_model\r\n        self.identified_params = {}\r\n        self.excitation_signals = self.generate_excitation_signals()\r\n\r\n    def generate_excitation_signals(self):\r\n        # Generate signals to excite all system modes\r\n        signals = {\r\n            'step_response': self.create_step_signals(),\r\n            'sine_sweep': self.create_sine_sweep_signals(),\r\n            'prbs': self.create_prbs_signals(),  # Pseudo-random binary sequence\r\n            'multi_sine': self.create_multi_sine_signals()\r\n        }\r\n        return signals\r\n\r\n    def identify_mass_properties(self):\r\n        # Identify mass, center of mass, and inertia\r\n        # Apply known forces and measure accelerations\r\n        forces = self.apply_known_forces()\r\n        accelerations = self.measure_accelerations()\r\n\r\n        # Estimate mass from F = ma\r\n        mass_estimate = self.estimate_mass(forces, accelerations)\r\n\r\n        # Estimate inertia through rotational tests\r\n        torques = self.apply_known_torques()\r\n        angular_accelerations = self.measure_angular_accelerations()\r\n        inertia_estimate = self.estimate_inertia(torques, angular_accelerations)\r\n\r\n        return {\r\n            'mass': mass_estimate,\r\n            'inertia': inertia_estimate,\r\n            'com_offset': self.estimate_com_offset()\r\n        }\r\n\r\n    def identify_friction_parameters(self):\r\n        # Identify static and dynamic friction\r\n        velocities = np.linspace(0, 2.0, 100)  # 0 to 2 m/s\r\n        friction_forces = []\r\n\r\n        for vel in velocities:\r\n            # Apply small force to maintain constant velocity\r\n            force = self.measure_steady_state_force(vel)\r\n            friction_forces.append(force)\r\n\r\n        # Fit friction model (e.g., LuGre, Coulomb + Viscous)\r\n        friction_params = self.fit_friction_model(velocities, friction_forces)\r\n        return friction_params\r\n\r\n    def identify_actuator_dynamics(self):\r\n        # Identify actuator response characteristics\r\n        input_signals = self.excitation_signals['sine_sweep']\r\n        output_responses = []\r\n\r\n        for signal in input_signals:\r\n            response = self.apply_and_measure(signal)\r\n            output_responses.append(response)\r\n\r\n        # Identify transfer function or state-space model\r\n        actuator_model = self.identify_transfer_function(input_signals, output_responses)\r\n        return actuator_model\r\n\r\n    def update_simulation_model(self):\r\n        # Update simulation with identified parameters\r\n        for param_name, param_value in self.identified_params.items():\r\n            self.robot_model.set_parameter(param_name, param_value)\r\n\r\n        print(\"Simulation model updated with identified parameters\")\n"})}),"\n",(0,i.jsx)(n.h2,{id:"transfer-learning-techniques",children:"Transfer Learning Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"fine-tuning-approaches",children:"Fine-Tuning Approaches"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import torch\r\nimport torch.nn as nn\r\n\r\nclass TransferLearningAgent:\r\n    def __init__(self, pretrained_policy_path):\r\n        # Load pre-trained policy from simulation\r\n        self.sim_policy = self.load_policy(pretrained_policy_path)\r\n        self.real_policy = self.create_real_robot_policy()\r\n\r\n        # Initialize with sim policy weights\r\n        self.initialize_real_policy_with_sim_weights()\r\n\r\n    def load_policy(self, path):\r\n        policy = torch.load(path)\r\n        return policy\r\n\r\n    def initialize_real_policy_with_sim_weights(self):\r\n        # Copy weights from sim policy to real policy\r\n        sim_state_dict = self.sim_policy.state_dict()\r\n        real_state_dict = self.real_policy.state_dict()\r\n\r\n        # Only copy matching layers\r\n        for name, param in sim_state_dict.items():\r\n            if name in real_state_dict and param.shape == real_state_dict[name].shape:\r\n                real_state_dict[name].copy_(param)\r\n\r\n    def adapt_policy_to_real_robot(self, real_data):\r\n        # Fine-tune policy with real robot data\r\n        optimizer = torch.optim.Adam(self.real_policy.parameters(), lr=1e-5)\r\n\r\n        for batch in real_data:\r\n            # Forward pass\r\n            actions_pred = self.real_policy(batch['observations'])\r\n\r\n            # Compute loss with real robot data\r\n            loss = self.compute_adaptation_loss(actions_pred, batch['actions'])\r\n\r\n            # Backward pass\r\n            optimizer.zero_grad()\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n    def compute_adaptation_loss(self, pred_actions, real_actions):\r\n        # Loss function for fine-tuning\r\n        action_loss = nn.MSELoss()(pred_actions, real_actions)\r\n\r\n        # Add regularization to prevent overfitting to small real dataset\r\n        l2_reg = sum(torch.norm(param) for param in self.real_policy.parameters())\r\n\r\n        total_loss = action_loss + 0.001 * l2_reg\r\n        return total_loss\n"})}),"\n",(0,i.jsx)(n.h3,{id:"domain-adaptation-networks",children:"Domain Adaptation Networks"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class DomainAdaptationNetwork(nn.Module):\r\n    def __init__(self, input_dim, hidden_dim=256):\r\n        super().__init__()\r\n\r\n        # Shared feature extractor\r\n        self.feature_extractor = nn.Sequential(\r\n            nn.Linear(input_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU()\r\n        )\r\n\r\n        # Sim-specific head\r\n        self.sim_head = nn.Sequential(\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, 1)  # Domain classifier output\r\n        )\r\n\r\n        # Real-specific head\r\n        self.real_head = nn.Sequential(\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, 1)  # Domain classifier output\r\n        )\r\n\r\n    def forward(self, x, domain='sim'):\r\n        features = self.feature_extractor(x)\r\n\r\n        if domain == 'sim':\r\n            return self.sim_head(features)\r\n        else:\r\n            return self.real_head(features)\r\n\r\n    def compute_domain_adaptation_loss(self, sim_features, real_features):\r\n        # Minimize domain discrepancy\r\n        domain_loss = nn.MSELoss()(sim_features, real_features)\r\n        return domain_loss\n"})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-sim-specific-transfer-techniques",children:"Isaac Sim-Specific Transfer Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"isaac-sim-calibration-tools",children:"Isaac Sim Calibration Tools"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core.utils.rotations import euler_angles_to_quat\r\nfrom omni.isaac.core.utils.prims import get_prim_at_path\r\n\r\nclass IsaacSimCalibrator:\r\n    def __init__(self, robot_prim_path):\r\n        self.robot_prim_path = robot_prim_path\r\n        self.calibration_data = {}\r\n\r\n    def calibrate_camera_intrinsics(self):\r\n        # Calibrate camera parameters to match real camera\r\n        camera_prim = get_prim_at_path(f"{self.robot_prim_path}/camera")\r\n\r\n        # Set focal length, principal point, distortion coefficients\r\n        # to match real camera specifications\r\n        camera_params = self.get_real_camera_params()\r\n\r\n        # Apply to Isaac Sim camera\r\n        self.set_camera_parameters(camera_prim, camera_params)\r\n\r\n    def calibrate_imu_parameters(self):\r\n        # Calibrate IMU noise and bias parameters\r\n        imu_params = self.identify_real_imu_params()\r\n\r\n        # Apply noise models in Isaac Sim\r\n        self.apply_imu_noise_model(imu_params)\r\n\r\n    def calibrate_joint_dynamics(self):\r\n        # Calibrate joint friction, damping, and compliance\r\n        joint_params = self.identify_real_joint_params()\r\n\r\n        for joint_name, params in joint_params.items():\r\n            joint_prim = get_prim_at_path(f"{self.robot_prim_path}/{joint_name}")\r\n            self.set_joint_dynamics(joint_prim, params)\r\n\r\n    def validate_calibration(self):\r\n        # Compare sim and real responses to validation inputs\r\n        sim_response = self.get_sim_response()\r\n        real_response = self.get_real_response()\r\n\r\n        error_metrics = self.compute_error_metrics(sim_response, real_response)\r\n        return error_metrics\n'})}),"\n",(0,i.jsx)(n.h3,{id:"sensor-simulation-calibration",children:"Sensor Simulation Calibration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class SensorCalibrator:\r\n    def __init__(self):\r\n        self.sensor_models = {}\r\n        self.calibration_params = {}\r\n\r\n    def calibrate_camera_sensor(self, real_camera_params):\r\n        # Match Isaac Sim camera to real camera\r\n        self.calibration_params['camera'] = {\r\n            'resolution': real_camera_params['resolution'],\r\n            'fov': real_camera_params['fov'],\r\n            'distortion_coefficients': real_camera_params['distortion'],\r\n            'noise_parameters': real_camera_params['noise']\r\n        }\r\n\r\n    def calibrate_lidar_sensor(self, real_lidar_params):\r\n        # Match Isaac Sim LiDAR to real LiDAR\r\n        self.calibration_params['lidar'] = {\r\n            'range_min': real_lidar_params['range_min'],\r\n            'range_max': real_lidar_params['range_max'],\r\n            'angular_resolution': real_lidar_params['angular_resolution'],\r\n            'noise_model': real_lidar_params['noise_model']\r\n        }\r\n\r\n    def calibrate_imu_sensor(self, real_imu_params):\r\n        # Match Isaac Sim IMU to real IMU\r\n        self.calibration_params['imu'] = {\r\n            'accelerometer_noise_density': real_imu_params['accelerometer_noise_density'],\r\n            'gyroscope_noise_density': real_imu_params['gyroscope_noise_density'],\r\n            'accelerometer_random_walk': real_imu_params['accelerometer_random_walk'],\r\n            'gyroscope_random_walk': real_imu_params['gyroscope_random_walk']\r\n        }\r\n\r\n    def apply_calibration(self, sensor):\r\n        # Apply calibration parameters to Isaac Sim sensor\r\n        sensor_type = sensor.get_sensor_type()\r\n        params = self.calibration_params.get(sensor_type, {})\r\n\r\n        for param_name, param_value in params.items():\r\n            sensor.set_parameter(param_name, param_value)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"real-world-deployment-strategies",children:"Real-World Deployment Strategies"}),"\n",(0,i.jsx)(n.h3,{id:"gradual-deployment",children:"Gradual Deployment"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class GradualDeployment:\r\n    def __init__(self, trained_policy):\r\n        self.policy = trained_policy\r\n        self.safety_controller = SafetyController()\r\n        self.performance_monitor = PerformanceMonitor()\r\n\r\n    def deploy_safely(self, real_robot):\r\n        # Phase 1: Teleoperation with policy suggestions\r\n        self.phase1_teleoperation_with_assistance(real_robot)\r\n\r\n        # Phase 2: Shared control with safety limits\r\n        self.phase2_shared_control(real_robot)\r\n\r\n        # Phase 3: Full autonomous operation\r\n        self.phase3_full_autonomy(real_robot)\r\n\r\n    def phase1_teleoperation_with_assistance(self, robot):\r\n        print("Phase 1: Policy provides suggestions, human has full control")\r\n\r\n        while True:\r\n            obs = robot.get_observations()\r\n            suggested_action = self.policy(obs)\r\n\r\n            # Human provides actual action\r\n            human_action = self.get_human_input()\r\n\r\n            # Blend human and suggested actions safely\r\n            safe_action = self.safety_controller.blend_actions(\r\n                human_action, suggested_action\r\n            )\r\n\r\n            robot.execute_action(safe_action)\r\n\r\n            # Monitor performance and safety\r\n            if self.performance_monitor.is_safe():\r\n                continue\r\n            else:\r\n                break\r\n\r\n    def phase2_shared_control(self, robot):\r\n        print("Phase 2: Policy executes, safety controller monitors")\r\n\r\n        while True:\r\n            obs = robot.get_observations()\r\n            action = self.policy(obs)\r\n\r\n            # Safety controller can override if needed\r\n            safe_action = self.safety_controller.ensure_safety(action, obs)\r\n\r\n            robot.execute_action(safe_action)\r\n\r\n            # Monitor performance\r\n            performance = self.performance_monitor.evaluate(obs, action)\r\n\r\n            if performance > 0.8:  # Good performance\r\n                # Increase policy autonomy\r\n                self.increase_autonomy()\r\n            else:\r\n                # Increase safety constraints\r\n                self.increase_safety()\r\n\r\n    def phase3_full_autonomy(self, robot):\r\n        print("Phase 3: Full autonomous operation")\r\n\r\n        # Policy runs with minimal intervention\r\n        while True:\r\n            obs = robot.get_observations()\r\n            action = self.policy(obs)\r\n\r\n            robot.execute_action(action)\r\n\r\n            # Emergency safety checks only\r\n            if self.safety_controller.detect_emergency(obs):\r\n                self.safety_controller.emergency_stop()\r\n                break\n'})}),"\n",(0,i.jsx)(n.h3,{id:"performance-monitoring-and-adaptation",children:"Performance Monitoring and Adaptation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class PerformanceMonitor:\r\n    def __init__(self):\r\n        self.metrics_history = {\r\n            'success_rate': [],\r\n            'execution_time': [],\r\n            'energy_efficiency': [],\r\n            'safety_violations': []\r\n        }\r\n        self.adaptation_threshold = 0.7\r\n\r\n    def evaluate_performance(self, observations, actions):\r\n        # Calculate various performance metrics\r\n        success = self.calculate_success_metric(observations, actions)\r\n        efficiency = self.calculate_efficiency_metric(observations, actions)\r\n        safety = self.calculate_safety_metric(observations, actions)\r\n\r\n        overall_performance = 0.4 * success + 0.4 * efficiency + 0.2 * safety\r\n        return overall_performance\r\n\r\n    def calculate_success_metric(self, obs, actions):\r\n        # Task-specific success calculation\r\n        task_completed = self.check_task_completion(obs)\r\n        return 1.0 if task_completed else 0.0\r\n\r\n    def calculate_efficiency_metric(self, obs, actions):\r\n        # Energy efficiency, time efficiency, etc.\r\n        energy_used = self.calculate_energy_consumption(actions)\r\n        time_taken = self.calculate_execution_time(obs)\r\n\r\n        # Normalize and return efficiency score\r\n        return self.normalize_efficiency(energy_used, time_taken)\r\n\r\n    def calculate_safety_metric(self, obs, actions):\r\n        # Calculate safety score (1.0 = completely safe)\r\n        safety_violations = self.count_safety_violations(obs, actions)\r\n        return max(0.0, 1.0 - safety_violations * 0.1)\r\n\r\n    def trigger_adaptation(self, current_performance):\r\n        # Trigger adaptation if performance drops below threshold\r\n        if current_performance < self.adaptation_threshold:\r\n            return True\r\n        return False\n"})}),"\n",(0,i.jsx)(n.h2,{id:"advanced-transfer-techniques",children:"Advanced Transfer Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"sim-to-real-with-real-to-sim-feedback",children:"Sim-to-Real with Real-to-Sim Feedback"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class BidirectionalTransfer:\r\n    def __init__(self):\r\n        self.sim_to_real_model = self.initialize_model()\r\n        self.real_to_sim_model = self.initialize_model()\r\n\r\n    def update_simulation_from_real_world(self, real_experience):\r\n        # Use real-world data to improve simulation accuracy\r\n        sim_improvements = self.analyze_real_experience(real_experience)\r\n\r\n        # Update simulation parameters based on real data\r\n        self.update_sim_parameters(sim_improvements)\r\n\r\n    def analyze_real_experience(self, real_data):\r\n        # Analyze where simulation differs from reality\r\n        discrepancies = {}\r\n\r\n        for state_action_pair in real_data:\r\n            sim_prediction = self.sim_model.predict(state_action_pair['state'])\r\n            real_outcome = state_action_pair['next_state']\r\n\r\n            discrepancy = real_outcome - sim_prediction\r\n            discrepancies[state_action_pair['state']] = discrepancy\r\n\r\n        return discrepancies\r\n\r\n    def update_sim_parameters(self, discrepancies):\r\n        # Adjust simulation parameters to reduce discrepancies\r\n        for state, discrepancy in discrepancies.items():\r\n            # Update relevant simulation parameters\r\n            self.adjust_friction_models(discrepancy)\r\n            self.adjust_dynamics_models(discrepancy)\r\n            self.adjust_sensor_models(discrepancy)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"few-shot-adaptation",children:"Few-Shot Adaptation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class FewShotAdapter:\r\n    def __init__(self, base_policy):\r\n        self.base_policy = base_policy\r\n        self.adaptation_network = self.create_adaptation_network()\r\n\r\n    def adapt_with_few_samples(self, real_task_data, num_samples=10):\r\n        # Adapt policy with minimal real-world samples\r\n        context = self.extract_context_from_data(real_task_data[:num_samples])\r\n\r\n        # Generate adapted policy parameters\r\n        adapted_params = self.adaptation_network(context)\r\n\r\n        # Apply adaptation to base policy\r\n        adapted_policy = self.apply_adaptation(self.base_policy, adapted_params)\r\n\r\n        return adapted_policy\r\n\r\n    def extract_context_from_data(self, data_batch):\r\n        # Extract task-relevant context from limited data\r\n        state_stats = self.compute_state_statistics(data_batch)\r\n        reward_stats = self.compute_reward_statistics(data_batch)\r\n        dynamics_model = self.estimate_local_dynamics(data_batch)\r\n\r\n        context = {\r\n            'state_stats': state_stats,\r\n            'reward_stats': reward_stats,\r\n            'dynamics_model': dynamics_model\r\n        }\r\n\r\n        return context\n"})}),"\n",(0,i.jsx)(n.h2,{id:"evaluation-and-validation",children:"Evaluation and Validation"}),"\n",(0,i.jsx)(n.h3,{id:"transfer-success-metrics",children:"Transfer Success Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class TransferEvaluator:\r\n    def __init__(self):\r\n        self.metrics = {\r\n            'success_rate': [],\r\n            'sample_efficiency': [],\r\n            'generalization_gap': [],\r\n            'safety_compliance': []\r\n        }\r\n\r\n    def evaluate_transfer_success(self, sim_policy, real_robot):\r\n        # Evaluate different aspects of transfer\r\n        success_rate = self.evaluate_success_rate(sim_policy, real_robot)\r\n        sample_efficiency = self.evaluate_sample_efficiency(sim_policy, real_robot)\r\n        generalization_gap = self.evaluate_generalization_gap(sim_policy, real_robot)\r\n        safety_compliance = self.evaluate_safety_compliance(sim_policy, real_robot)\r\n\r\n        results = {\r\n            'success_rate': success_rate,\r\n            'sample_efficiency': sample_efficiency,\r\n            'generalization_gap': generalization_gap,\r\n            'safety_compliance': safety_compliance\r\n        }\r\n\r\n        return results\r\n\r\n    def evaluate_success_rate(self, policy, robot, num_trials=100):\r\n        successes = 0\r\n        for trial in range(num_trials):\r\n            success = self.run_single_trial(policy, robot)\r\n            if success:\r\n                successes += 1\r\n        return successes / num_trials\r\n\r\n    def evaluate_sample_efficiency(self, policy, robot):\r\n        # Measure how quickly policy adapts to real robot\r\n        initial_performance = self.evaluate_policy(robot, policy)\r\n\r\n        adaptation_curve = []\r\n        for samples in range(0, 1000, 50):  # Every 50 samples\r\n            adapted_policy = self.adapt_policy_with_samples(policy, robot, samples)\r\n            performance = self.evaluate_policy(robot, adapted_policy)\r\n            adaptation_curve.append((samples, performance))\r\n\r\n        return adaptation_curve\r\n\r\n    def compute_generalization_gap(self, sim_performance, real_performance):\r\n        # Difference between sim and real performance\r\n        return sim_performance - real_performance\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-for-successful-transfer",children:"Best Practices for Successful Transfer"}),"\n",(0,i.jsx)(n.h3,{id:"pre-transfer-validation",children:"Pre-Transfer Validation"}),"\n",(0,i.jsx)(n.p,{children:"Before deploying a simulated policy on real hardware:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Extensive simulation testing"}),": Test policy under various randomized conditions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Physics validation"}),": Verify simulation physics match real-world behavior"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Safety checks"}),": Implement emergency stop and safety constraints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gradual deployment"}),": Start with teleoperation, move to shared control, then autonomy"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"continuous-improvement",children:"Continuous Improvement"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Online adaptation"}),": Continuously adapt policy based on real-world performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data collection"}),": Collect real-world data to improve simulation models"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"A/B testing"}),": Compare different transfer strategies"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Human feedback"}),": Incorporate human corrections and preferences"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The success of sim-to-real transfer in humanoid robotics depends on careful attention to the reality gap, proper calibration, and systematic validation procedures that ensure safe and effective deployment of simulation-trained policies on real hardware."})]})}function _(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>o});var a=r(6540);const i={},s=a.createContext(i);function t(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);